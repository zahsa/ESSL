{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/noah/.conda/envs/essl/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4383/846313018.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0mbackbone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlargerCNN_backbone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0mmodel_init\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfinetune_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbackbone\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackbone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackbone\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m trainloader = torch.utils.data.DataLoader(data.train_data,\n\u001b[0m\u001b[1;32m     36\u001b[0m                                                   batch_size=256, shuffle=True)\n\u001b[1;32m     37\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "# libraries\n",
    "import copy\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits import mplot3d\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision.datasets as datasets\n",
    "from tqdm import tqdm\n",
    "\n",
    "matplotlib.rcParams['figure.figsize'] = [18, 12]\n",
    "# code from this library - import the lines module\n",
    "import loss_landscapes\n",
    "import loss_landscapes.metrics\n",
    "\n",
    "from essl.backbones import largerCNN_backbone\n",
    "from essl.evaluate_downstream import finetune_model\n",
    "from essl.datasets import Cifar10\n",
    "import torch\n",
    "\n",
    "# contour plot resolution\n",
    "STEPS = 40\n",
    "\n",
    "backbone = largerCNN_backbone()\n",
    "model = finetune_model(backbone.backbone, backbone.in_features, 10)\n",
    "model_path = \"/home/noah/ESSL/exps/Explainability/loss_landscape/exp1_0/worst/model.pt\"\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "model\n",
    "\n",
    "backbone = largerCNN_backbone()\n",
    "model_init = finetune_model(backbone.backbone, backbone.in_features, 10)\n",
    "data = Cifar10()\n",
    "trainloader = torch.utils.data.DataLoader(data.train_data,\n",
    "                                                  batch_size=256, shuffle=True)\n",
    "X, y = iter(trainloader).__next__()\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "metric = loss_landscapes.metrics.Loss(criterion, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute loss data\n",
    "loss_data = loss_landscapes.linear_interpolation(model_init, model, metric, STEPS, deepcopy_model=True)\n",
    "\n",
    "plt.plot([1/STEPS * i for i in range(STEPS)], loss_data)\n",
    "plt.title('Linear Interpolation of Loss')\n",
    "plt.xlabel('Interpolation Coefficient')\n",
    "plt.ylabel('Loss')\n",
    "axes = plt.gca()\n",
    "# axes.set_ylim([2.300,2.325])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_data_fin = loss_landscapes.random_plane(model, metric, 10, STEPS, normalization='filter', deepcopy_model=True)\n",
    "plt.contour(loss_data_fin, levels=50)\n",
    "plt.title('Loss Contours around Trained Model')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = plt.axes(projection='3d')\n",
    "X = np.array([[j for j in range(STEPS)] for i in range(STEPS)])\n",
    "Y = np.array([[i for _ in range(STEPS)] for i in range(STEPS)])\n",
    "ax.plot_surface(X, Y, loss_data_fin, rstride=1, cstride=1, cmap='viridis', edgecolor='none')\n",
    "ax.set_title('Surface Plot of Loss Landscape')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "essl",
   "language": "python",
   "name": "essl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
